#include "qffmpeg.h"
#include "algothread.h"
#include <QDateTime>
#include <QDebug>

extern buffNode imageBuff[];

QFFmpeg::QFFmpeg(QObject *parent) :
    QObject(parent)
{    

}

bool QFFmpeg::fileInit(){
    av_register_all();//注册所有组件
    //参数1:封装格式上下文->AVFormatContext->包含了视频信息(视频格式、大小等等...)双指针定义一颗星*，
    //参数2:要打开流的路径（文件名）
    //AVFormatContext保存视频（视频流）相关信息的结构体
    formatContent = avformat_alloc_context();
    int res = avformat_open_input(&formatContent,url.toStdString().c_str(),nullptr,nullptr);//打开摄像头

    if(res!=0)
    {
        qDebug()<<"打开视频失败";
        return false;
    }

    /*3、打开成功之后相关的结构体信息放在了formatContent里面，接下来获取视频文件信息*/
    //3.1先看有没有视频流信息（avformat_find_stream_info），进行判断的原因是有可能打开普通文件
    res = avformat_find_stream_info(formatContent,nullptr);
    if(res<0)
    {
        qDebug()<<"打开流媒体信息失败";
        return false;
    }

    videoType = -1;
    //3.2一个视频中有多股码流（用循环），存在AVFormatContext的streams数组中
    for(int i=0;i<formatContent->nb_streams;i++)
    {
        if(formatContent->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO)//streams->有AVStream结构体,AVStream->codec
        {
            //找到视频流(只有一个)
            videoType = i;//标识视频流这个类型
            break;
        }
    }
    if(videoType == -1)
    {
        qDebug()<<"没有找到视频流相关信息";
        return false;
    }

    //3.3根据视频流查找编码器对应的上下文对象结构体，存储编码器以及宽高格式等
    codec = formatContent->streams[videoType]->codec;
    /*4、有视频流，则查找对应视频流的解码器*/
    AVCodec *decoder = avcodec_find_decoder(codec->codec_id);//需要解码器的id
    if(decoder ==nullptr)
    {
        qDebug()<<"没有找到对应的解码器";
        return false;
    }

    /*5、找到解码器后打开解码器*/
    //参数：1.初始化的上下文对象 2.打开的解码器 3.类似目录的东西（没有）
    res = avcodec_open2(codec,decoder,nullptr);
    if(res!=0)
    {
        qDebug()<<"解码器打开失败";
        return false;
    }

    /*6、获取到的每一帧码流（视频流）数据写到文件中，进行循环解码*/
    AVPacket *pkt=&pktContent;

    //码流数据是存到buffer里面，也需要我们动态开空间(AVBufferRef *buf;)
    //开空间不知道一帧的码流数据是多少？其实编解码器告诉了宽高，以此可以计算出给码流数据开多大空间
    int bufSize = codec->width*codec->height;//计算一帧（图）数据的大小
    av_new_packet(pkt,bufSize);

    pictureRGB = nullptr;//保存解码及剔除后的像素数据（做准备）
    pictureRGB = av_frame_alloc();
    pictureRGB->width = codec->width;
    pictureRGB->height = codec->height;
    pictureRGB->format = codec->pix_fmt;//格式的设置

    //获取解码后的一帧像素数据有多大
    int numByte = avpicture_get_size(AV_PIX_FMT_RGB32,codec->width,codec->height);
    //开的空间用来保存像素数据的大小
    uint8_t *buffer = (uint8_t *)av_malloc(numByte*sizeof(uint8_t));
    //像素数据填充到AVFrame的pictureRGB里
    avpicture_fill((AVPicture *)pictureRGB,buffer,AV_PIX_FMT_RGB32,codec->width,codec->height);
    //因为解码之后要伸展，所以先进行转换规则的设置，转换完进入第七步解码
    swsContent = nullptr;
    swsContent = sws_getContext(codec->width,codec->height,codec->pix_fmt,
                                    codec->width,codec->height,AV_PIX_FMT_RGB32,
                                    SWS_BICUBIC,nullptr,nullptr,nullptr);

    qDebug()<<"初始化视频文件成功";
    return true;
}

int QFFmpeg::filePlay()
{
    mutex.lock();
    int result=1;

    AVPacket *pkt=&pktContent;
    //av_read_frame()参数：1最初保存信息的结构体 2包
    int count = 0;//保存帧数的变量
    if(av_read_frame(formatContent,pkt) >= 0)//成功读到了数据（一帧一帧读（循环）：av_read_frame）
    {
        /*6.2AVPacket->AVStream，要判断读到的每一帧的码流数据是不是视频流*/
        if(pkt->stream_index == videoType)
        {
            //是视频流则写到文件中
            //            fwrite(pkt->data,pkt->size,1,fp);//每次写一个结构体
            //读到一帧是视频流就进行解码的动作
            /*7、解码——得到RGB保存在AVFrame结构体里*/
            //参数：1编解码器上下文对象的结构体 2存放解码后的像素数据（AVFrame类型）
            //3判断有没有数据可以进行解码：指针类型的变量 4对谁进行解码：一帧的码流数据
            //功能：把得到的一帧码流数据用编解码器上下文对象去解，存放在AVFrame结构体里
            int got_picture_ptr = -1;

            avcodec_decode_video2(codec,pictureRGB,&got_picture_ptr,pkt);
            if(got_picture_ptr != 0)
            {
                //把解码得到的损坏的像素数据剔除(存到pictureRGB中)
                sws_scale(swsContent,pictureRGB->data,pictureRGB->linesize,0,pictureRGB->height,
                          pictureRGB->data,pictureRGB->linesize);

                memcpy(imageBuff[channel-1].image,pictureRGB->data,codec->width*codec->height*4);
                imageBuff[channel-1].width=codec->width;
                imageBuff[channel-1].height=codec->height;
                imageBuff[channel-1].format=QImage::Format_RGB32;

            }
        }
        //每次都存在同一块内存空间里，要清空上一次的操作
        av_packet_unref(pkt);//不是free
    }
    mutex.unlock();
    return result;
}

QFFmpeg::~QFFmpeg()
{
    if(hostType==0){
        avformat_free_context(pAVFormatContext);
        av_frame_free(&pAVFrame);
        sws_freeContext(pSwsContext);
    }else{
        avformat_free_context(formatContent);
        av_frame_free(&pictureRGB);
        sws_freeContext(swsContent);
    }

}

bool QFFmpeg::rtspInit()
{
    videoStreamIndex=-1;
    av_register_all();//注册库中所有可用的文件格式和解码器

    avformat_network_init();//初始化网络流格式,使用RTSP网络流时必须先执行
    pAVFormatContext = avformat_alloc_context();//申请一个AVFormatContext结构的内存,并进行简单初始化
    pAVFrame=av_frame_alloc();

    AVDictionary* options = NULL;
    av_dict_set(&options, "rtsp_transport", "tcp", 0);
    av_dict_set(&options, "stimeout", "2000000", 0);
    av_dict_set(&options, "max_delay", "500000", 0);
    av_dict_set(&options, "thread_queue_size", "512", 0);

    //打开视频流
    int result=avformat_open_input(&pAVFormatContext, url.toStdString().c_str(),NULL,&options);
    if (result<0){
        qDebug()<<"打开视频流失败";
        return false;
    }
    //获取视频流信息
    result=avformat_find_stream_info(pAVFormatContext,NULL);
    if (result<0){
        qDebug()<<"获取视频流信息失败";
        return false;
    }

    //获取视频流索引
    videoStreamIndex = -1;
    for (uint i = 0; i < pAVFormatContext->nb_streams; i++) {
        if (pAVFormatContext->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoStreamIndex = i;
            break;
        }
    }

    if (videoStreamIndex==-1){
        qDebug()<<"获取视频流索引失败";
        return false;
    }

    //获取视频流的分辨率大小
    pAVCodecContext = pAVFormatContext->streams[videoStreamIndex]->codec;
    videoWidth=pAVCodecContext->width;
    videoHeight=pAVCodecContext->height;

    avpicture_alloc(&pAVPicture,AV_PIX_FMT_RGB24,videoWidth,videoHeight);

    AVCodec *pAVCodec;

    //获取视频流解码器
    pAVCodec = avcodec_find_decoder(pAVCodecContext->codec_id);

    //AVPixelFormat fmt=pAVCodecContext->pix_fmt;

    pSwsContext = sws_getContext(videoWidth,videoHeight,AV_PIX_FMT_YUV420P,videoWidth,videoHeight,AV_PIX_FMT_RGB24,SWS_BICUBIC,0,0,0);
    //pSwsContext = sws_getContext(videoWidth,videoHeight,AV_PIX_FMT_YUV420P,videoWidth,videoHeight,AV_PIX_FMT_RGB32,SWS_BICUBIC,0,0,0);

    //打开对应解码器
    result=avcodec_open2(pAVCodecContext,pAVCodec,NULL);
    if (result<0){
        qDebug()<<"打开解码器失败";
        return false;
    }    

    qDebug()<<"初始化视频流成功";
    return true;
}

int QFFmpeg::rtspPlay()
{
    mutex.lock();
    int result=1;

    int frameFinished=0;
        if (av_read_frame(pAVFormatContext, &pAVPacket) >= 0){
            if(pAVPacket.stream_index==videoStreamIndex){
                //qDebug()<<"开始解码"<<QDateTime::currentDateTime().toString("yyyy-MM-dd HH:mm:ss");
                avcodec_decode_video2(pAVCodecContext, pAVFrame, &frameFinished, &pAVPacket);
                sws_scale(pSwsContext,(const uint8_t* const *)pAVFrame->data,pAVFrame->linesize,0,
                          videoHeight,pAVPicture.data,pAVPicture.linesize);

                memcpy(imageBuff[channel-1].image,pAVPicture.data[0],videoWidth*videoHeight*3);
                imageBuff[channel-1].width=videoWidth;
                imageBuff[channel-1].height=videoHeight;
                imageBuff[channel-1].format=QImage::Format_RGB888;
                //QImage image(pAVPicture.data[0],videoWidth,videoHeight,QImage::Format_RGB888);
                //emit sendtoShow(channel,image);
            }
        }else{
            printf("over\n");
            result=-1;
        }
        av_free_packet(&pAVPacket);//释放资源,否则内存会一直上升
    mutex.unlock();
    return result;
}
